%!TEX root = article.tex

\section{OT distances from sample streams}

We introduce an online adapation of the Sinkhorn algorithm in this section. We
wish to construct an estimator of $\Ww(\alpha,\beta)$ from multiple sets of
samples $(\hat \alpha^t)_t = \frac{1}{n} \sum_{i=1}^n \delta_{x_i^t}$
 and similar $(\hat \beta^t)_t$. This estimator should
successively use these samples to enrich a representation of the solution of
\eqref{eq:dual}, that may be arbitrary complex. $(\hat \alpha_n^t)_t$ and $(\hat
\beta_n^t)_t$ may be seen as mini-batches within a training procedure, or as a
temporal stream. We first introduce the intuitions behind the construction of
our algorithm, before casting it as a non-convex stochastic mirror descent.

\subsection{Online Sinkhorn iterations}

From \eqref{eq:dual}, along the Sinkhorn optimisation trajectory, the potential $f_t$ is always the negative logarithm an
infinite mixture of kernel functions $\kappa_y: x \to \exp(-\frac{C(\cdot, y)}{\varepsilon})$:
\begin{equation}
    \exp(-\frac{f_t(\cdot)}{\varepsilon}) = 
    \int_{y \in \Yy} \exp(g_t(y))  \exp(-\frac{C(\cdot, y)}{\epsilon}) \d \beta(y),
\end{equation}
and similarly for $g_t$. Our algorithm will construct a sequence $(\hat f_t,
\hat g_t)$ that behaves like $g_t$ and $f_t$ in the long run. The strong
structural property of the continuous potentials suggests to express $\exp(-\frac{\hat f_t(\cdot)}{\varepsilon})$ as a
finite mixture of kernel functions. That is, $\hat f_t$ and $\hat g_t$ are continuous
functions constructed respectively from the weights ${(q_i^t)}_{i,s}, {(p_i^s)}_{i,s} > 0$ and positions
${(y_i^s)}_{i,t} \in~\Yy, {(x_i^s)}_{i,s\leq t} \in~\Xx$:
\begin{align}\label{eq:param}
    \hat f_t(\cdot) &= - \varepsilon \log \sum_{s=1}^t \sum_{i=1}^{n} 
    \exp(\frac{q_i^s - C(\cdot, y_i^s)}{\varepsilon}) \\
    \hat g_t(\cdot) &= - \varepsilon \log \sum_{s=1}^t \sum_{i=1}^{n} 
    \exp(\frac{p_i^s - C(x_i^s, \cdot)}{\varepsilon}).
\end{align}
Provided with fresh samples $(x_i^{t+1})_i$ and $(y_i^{t+1})_i$, a naive approach
 updates the potentials using a noisy soft C-transform:
\begin{equation}
    \hat f_{t+1} = T_{C,\varepsilon}(g_t, \hat \beta_t),\qquad g_{t+1} = T_{C,\varepsilon}(\hat f_{t+1}, \hat \alpha_t),
\end{equation}
which translates into setting all $(p_i^s)_{s \leq t}$ to 0, and to set each weight
 $q_i^{t+1}$ to $g_t(y_i^{t+1}) - \varepsilon \log(n_t)$, and similarly for $p_i^t$.

The variance of these updates does not reduce: this algorithm does nos
converge. It is however possible to show, through contractance of the random
operator $T{(\cdot, \hat \beta)}_t$, that the Markov chain $(f_t, g_t)$ that it
defines converges towards a stationary distribution that does not depend on
initialisation.

We must therefore take more cautions steps---in other words,
we cannot afford to forget past iterates to obtain a consistent estimation of
potentials. We introduce a learning rate in Sinkhorn iterations, that averages
the past representations and the newly computed noisy C-transforms.
\begin{equation}\label{eq:updates}
    \exp(-\frac{\hat f_{t+1}}
    {\varepsilon}) = (1 - \eta_t) \exp(-\frac{\hat f_t}{\varepsilon}) 
    + \eta_t 
    \exp(-\frac{T(g_t, \hat \beta_t)}{\varepsilon}),
\end{equation}
and similarly for $g_t$. Performing the averaging in the space of
$\exp(-\frac{\hat f_{t}}{\varepsilon})$ yields simple updates for the weights
${(p_i^s)}_s$, and is crucial for our theoretical understanding. In essence, the
weights of past samples are reduced by a constant factor, while new weights are
computed from the evaluation of $g_t(\cdot)$ at points $y_i^t$. Note that we
perform \textit{simultenous updates} of $f_t$ and $g_t$, once again from
theoretical considerations.

\begin{algorithm}[t]
    \begin{algorithmic}
    \Input Distribution $\alpha$ and $\beta$, $\varepsilon$, learning weights ${(\eta_t)}_t$,
    \State Initialize $\Pp = [\:]$, $\Qq = [\:]$, $\bar \alpha = 0$, $\bar \beta = 0$
    \For{$t =0, \dots, T$}
        \For{$p \in \Pp$, $q \in \Qq$}
            \State $p \gets p + \varepsilon \log(1 - \eta_t)$,
             \State $q \gets q + \varepsilon \log(1 - \eta_t)$
        \EndFor
        \State Sample $(x_i^t)_{i=1,n} \sim \alpha$, $(y_i^t)_{i=1,n} \sim \beta$
        \For{$y \in y_1^t, \dots,y_n^t$, $x \in x_1^t, \dots,x_n^t$}
            \State $q_i^t \gets 
            - \varepsilon \log \frac{\eta_t}{n_t} 
            \sum_{x \in \bar \alpha, p \in \Pp} \exp(\frac{p - C(x, y_i^t)}{\varepsilon})$
            \State $p_i^t \gets 
            - \varepsilon \log \frac{\eta_t}{n_t} 
            \sum_{y \in \bar \beta, q \in \Qq} \exp(\frac{q - C(x_i^t, y)}{\varepsilon})$
        \EndFor
        \State \textit{Optional}: refit all $q_i^t = g_t(y_i^t) - \varepsilon \log (nt)$
        \State\hspace{2.45cm} $p_i^t = f_t(x_i^t) - \varepsilon \log (nt)$
        \State Add ${(x_i^t)}_i$ to $\bar \alpha$, ${(y_i^t)}_i$ to $\bar \beta$
        \State Add $(q_i^t)_i$ to $\Qq$, $(p_i^t)_i$ to $\Pp$
    \EndFor
    \State Returns representations of $f_T: (\bar \beta, \Qq)$ and $g_T: (\bar \alpha, \Pp)$, 
    \end{algorithmic}
    \caption{Online Sinkhorn}\label{alg:online_sinkhorn}
\end{algorithm}

\subsection{Algorithm, complexity, refinements}

We provide the pseudo-code of online Sinkhorn in \autoref{alg:online_sinkhorn}.
We denote $\bar \beta$ and $\bar \alpha$ the empirical distributions made of all
previously seen samples $(x_i^s)_{i, s \leq t}$ and $(y_i^s)_{i, s \leq t}$, and
assimilate them to a set in the pseudo-code. The iteration~$t$ has a complexity in $\Oo(t\,n^2)$,
due to the evaluation of the distances $C(x_i^t, y_i^s)$ for all $s < t$, and to
the computation of the C-transforms. Online Sinkhorn constructs the distance
matrix $C$ on the fly, parallel to updating the potentials $f$ and $g$. In
total, its computation cost after seeing $N$ samples is $\Oo(N^2)$, and its
memory cost is $\Oo(N)$. We propose some heuristic refinements to accelerate convergence and alleviate computational cost.


\paragraph{Fully-corrective scheme.} The potentials $(f_t)$ and $(\beta_t)$ may be
improved by refitting the weights $(p_i^s)_{s\leq t}$, $(q_i^s)_{s\leq t}$ based
on the previously seen samples $(x_i^s)_{s\leq t}$, $(y_i^t)_{s\leq t}$. This
amounts to replace, for all $s \leq t$, $j \in [1, n]$
\begin{align}
    q_j^v &= g_t(y_j^v) - \varepsilon \log(n t) \\
    &= - \varepsilon \log \frac{1}{nt} \sum_{s=1}^t 
    \sum_{i=1}^n \exp(\frac{p_i^s - C(x_i^s, y_j^v)}{\varepsilon}),
\end{align}
and similarly for $q_i^v$. This is exactly performing one step of the discrete Sinkhorn
 algorithm for distributions $\bar \alpha$ and $\bar \beta$. This will reduce the dual cost
 $F_{ \bar \alpha, \bar \beta}(f_t, g_t)$, and we hope for the energy $F_{\alpha,
 \beta}$ to decrease as well. Of course, this reweighted scheme (akin to the
 fully-reweighted Frank-Wolfe scheme \cite{}) has a cost in $\Oo(t^2 n^2)$. It
 may be used every $k$ iterations, with $k$ increasing with $t$.

\paragraph{Memory compression.} The memory requirement in $\Oo(N)$ is an
avoidable limitation of the algorithm, which cannot be avoided sas the optimal
potentials $(f^\star, g^\star)$ do not admit a parametric representation in
general. However, we may compress the representations $(\bar \alpha, \Pp)$ and
$(\bar \beta, \Qq)$. We propose to perform $k$-means clustering over $M$
centroids. The sampled points $(x_i^s)_{s\leq t}$, $(y_i^t)_{s\leq t}$ are
attached to centroids ${(\bar x_i)}_M$ and ${(\bar y_i)}_M$. For all $I \in
[M]$, we set weights and potentials as
\begin{align}
    q_I &= - \varepsilon \log \sum_{\substack{y_i^t \text{closest}\\\text{to } \bar y_I}}
     \exp(\frac{q_i^t}{\varepsilon}),\\
    f_t(\cdot) &= - \varepsilon \log\sum_{I=1}^M \exp(\frac{q_I - C(\cdot, \bar y_I)}{\varepsilon}),
\end{align}
and similarly for $(p_I)_I$ and ${(g_t)}_t$.

\paragraph{Out-of-loop averaging and sampling.} Optionally, we may also
compute out-of-loop averages of potentials
\begin{align}
    \exp(-\bar f_{t+1}) = (1 - \gamma_t) \exp(-\bar f_t) + \gamma_t \exp(-\hat f_t), \\
    \exp(-\bar g_{t+1}) = (1 - \gamma_t) \exp(-\bar g_t) + \gamma_t \exp(-\hat g_t),
\end{align}
to further reduce the estimation variance. We will see that this averaging is
useful in practice. Finally, we note that our algorithm can be run of discrete
$\alpha$ and $\beta$, in which case we can tabulate $p$, $q$. The resulting
algorithm is a \textit{subsampled} Sinkhorn algorithm for histograms, that we provide in the
appendix.

\subsection{A non-convex stochastic mirror descent}

Online Sinkhorn corresponds to a stochastic mirror descent algorithm applied to
the objective function $F_{\alpha, \beta}$. To see it, we first apply a change
of variable in \eqref{eq:wass}, setting $\mu \triangleq \alpha \exp(-f /
\varepsilon)$, $\nu \triangleq \beta \exp(-g / \varepsilon)$. The dual problem solution 
$F_{\alpha, \beta}^\star$
rewrites as a minimisation problem over positive measures on $\Xx$ and $\Yy$:
\begin{equation}\label{eq:wass_reparam}
    - \varepsilon \!\!\!\!\min_{\substack{\mu \in \Mm^+(\Xx) \\ 
    \nu \in \Mm^+(\Yy)}} \!\!\!\KL(\alpha | \mu)
    + \KL(\beta | \nu) + \dotp{\mu \otimes \nu}{\exp(-\frac{C}{\varepsilon})} - 1,
\end{equation}
where the function $\KL: \Pp(\Xx) \times \Mm^+(\Xx) \triangleq \dotp{\alpha}{
    \log \frac{\d \alpha}{\d \mu}}$ is the Kullback-Lieber divergence between
$\alpha$ and $\mu$. This objective is block convex in $\mu$, $\nu$, but not jointly convex. As it is defined on \textit{Banach} spaces, we can solve it using stochastic mirror descent. For this, we define the (convex) distance generating function $\Mm^+(\Xx) \times \Mm^+(\Yy) \to \RR$:
\begin{equation}
    \omega(\mu, \nu) \triangleq \KL(\alpha | \mu) + \KL(\beta | \nu).
\end{equation}
The gradient of this function and of its Fenchel conjugate $\omega^\star: \Cc(X)
\times \Cc(\Yy) \to \RR$ yields two \textit{mirror maps}. For all $\mu, \nu \in
\Mm^+(\Xx) \times \Mm^+(\Yy)$, $p, q \in \Cc(\Xx) \times \Cc(\Yy)$,
\begin{equation}
    \nabla \omega(\mu, \nu) = - \frac{\d \alpha}{\d \mu}
    \qquad \nabla \omega^\star(p, q) = (-\frac{\alpha}{p}, -\frac{\beta}{q}).
\end{equation}
 should be an unbiased estimation
of the true gradient $\nabla F(\mu, \nu)$ of the objective function~\eqref{eq:wass_reparam}.
For all $x \in \Xx$, this gradient reads
\begin{equation}
    \nabla_\mu F(\mu, \nu) = \exp(-\frac{f}{\varepsilon}) - 
    \int_{y \in \Yy} \exp(\frac{g(y) - C(x, y)}{\varepsilon})\d \beta(y),
\end{equation}
where $f$ and $g$ are the potentials associated to $f$ and $g$. $\beta$ may be
replaced by a sampled $\beta$ to obtain an unbiased estimation $\tilde \nabla
F(\mu, \nu)$of $\nabla F(\mu, \nu)$. The stochastic mirror descent update
% 
\begin{equation}
    \mu_t, \nu_t = \nabla \omega^\star\Big( \nabla \omega(\mu_t, \nu_t) - 
    \eta_t \tilde \nabla F_\alpha, \beta(\mu, \nu)\Big),
\end{equation}
then exactly yield the updates \eqref{eq:updates}. 

A few comments are in order. First, the objects $\mu_t$ and $\nu_t$ are abstract
objects that are never represented in memory. Instead, their associated
potentials $f_t$ and $g_t$ are parametrized as \eqref{eq:param}. In particular,
$\mu_t$ and $\nu_t$ remains absolutely continuous with respect to $\alpha$ and
$\beta$ respectively, so that the Kullbach-Liebler divergence remain finite.


% Estimator $\dotp{\alpha}{-\log \EE[\exp(-\hat f)]} + \dotp{\beta}{-\log \EE[\exp(-\hat g)]}$

% - estimator properties

% \subsection{Online Sinkhorn convergence}

% - slowed down Sinkhorn convergence

% - Random iterated functions

% - Combining both

% \subsection{Non-convex mirror descent}

% \section{Experiments}

% \subsection{Offline distance averaging}

% \subsection{Online distance computations}

% \subsection{Training generative models}



