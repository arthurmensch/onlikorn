\documentclass[a4paper, 10pt]{article}
\input{preamble.tex}

\addbibresource{biblio.bib}

\begin{document}

\section{Online Sinkhorn}

The Sinkhorn objective rewrites
\begin{equation}
    \max_{f, g \in \Cc(\Xx)} \dotp{f}{\alpha} + \dotp{g}{\beta}
     - \epsilon \dotp{\alpha \otimes \beta}{\exp(-\frac{f \oplus g - C}{\epsilon})
     }
\end{equation}
We perform the following change of variable $\mu = \alpha e^{f / \varepsilon}$,
$\nu = \beta e^{g / \epsilon}$, to obtain the equivalent problem, in $\Mm^+(\Xx)$
\begin{equation}
    \min_{\mu,\nu \in \Mm^+(\Xx)} \KL(\alpha|\mu) + \KL(\beta|\mu) + 
    \epsilon \dotp{\mu \otimes \nu}{\exp(-\frac{C}{\epsilon})} \triangleq f(\mu, \nu).
\end{equation}

The problem is not jointly convex, but convex in $\mu$ and $\nu$.
We may approach this problem from a game point of view of finding
 a local Nash equilibrium $(\mu^\star,\nu^\star)$ such that
\begin{align}\label{eq:Nash}
    \mu^\star &= \argmin_{\mu \in V(\mu^\star)} \Ff(\mu, \nu^\star) \\
    \nu^\star &= \argmin_{\nu \in V(\nu^\star)} \Ff(\mu^\star, \nu),
\end{align}
where $V$ are open sets. Such a formalism is useful as results on mirror descent
convergence in multi-agent setting exist for this problem. To solve
\eqref{eq:Nash}, we need to define distance generating functions to move back
and forth from $\mu$ and $\nu$ and their dual form. We define
\begin{align}
    \omega_\alpha(\mu) &\triangleq \KL(\alpha | \mu) \\
    \omega_\beta(\nu) &\triangleq \KL(\beta | \nu) \\
\end{align},
associated the the mirror maps
\begin{align}
    \nabla_\mu \omega_\alpha(\mu) &= 
    - \frac{\d\alpha}{\d\mu} \qquad \big( = - \exp(-f / \epsilon) \big), \\
    \nabla_\nu \omega_\beta(\nu) &= 
    - \frac{\d\beta}{\d\nu} \qquad \big( = - \exp(-g / \epsilon) \big),
\end{align}
with inverse
\begin{align}
    \nabla_\mu \omega^\star_\alpha(p) &= - \frac{\alpha}{p}, \\
    \nabla_\nu \omega^\star_\beta(q) &= - \frac{\beta}{q}.
\end{align}
\paragraph{Algorithm.} Let us consider the simple simultaneous mirror descent setting, where we build
the sequence of iterate $(\mu_t, \nu_t)_t$. It is easy to shows that if we start
from $\mu_0 \gg \alpha$ and $\nu_0 \gg \beta$, the iterates will remain
absolutely continuous with respect to $\alpha$ and $\beta$. We will therefore
write $\mu_t = \alpha e^{f_t / \varepsilon}$, $\nu_t = \beta e^{g_t /
\epsilon}$. The mirror descent iterations rewrite (for $\mu$)
\begin{equation}
    \mu_{t+1} = \frac{\alpha}{e^{-f_t / \epsilon} + \eta \nabla_\mu \Ff(\mu_t, \nu_t)},
\end{equation}
with $\nabla_\mu \Ff(\mu_t, \nu_t) = - \exp(-\frac{f_t}{\epsilon})+ \epsilon
\int_y \exp(\frac{g(y)-C(\cdot, y)}{\epsilon})\d\beta(y)$. We therefore have the
following update rules
\begin{align}
    \exp(-\frac{f_{t+1}}{\epsilon}) &=
     (1 - \eta) \exp(-\frac{f_{t}}{\epsilon}) 
     + \eta \EE_\beta[\epsilon \exp( \frac{g_t(y)-C(\cdot, y)}{\epsilon})], \\
     \exp(-\frac{g_{t+1}}{\epsilon}) &=
     (1 - \eta) \exp(-\frac{g_{t}}{\epsilon}) 
     + \eta \EE_\alpha[\epsilon \exp( \frac{f_t(x)-C(x, \cdot)}{\epsilon})].
\end{align}
Assuming we sample $\hat \beta_t = \sum_{i=1}^n b_{i,t} \delta_{y_{i,t}}$ and
$\hat \alpha_t = \sum_{i=1}^n a_{i,t} \delta_{x_{i,t}}$, we can approximate the
expectations above, and expect, with decreasing step-sizes to achieve
convergence.

Some variants (more likely to converge better) may be considered. The alternated variant writes
\begin{align}
    \exp(-\frac{f_{t+1}}{\epsilon}) &=
     (1 - \eta) \exp(-\frac{f_{t}}{\epsilon}) 
     + \eta \EE_\beta[\epsilon \exp( \frac{g_t(y)-C(\cdot, y)}{\epsilon})], \\
     \exp(-\frac{g_{t+1}}{\epsilon}) &=
     (1 - \eta) \exp(-\frac{g_{t}}{\epsilon}) 
     + \eta \EE_\alpha[\epsilon \exp( \frac{f_{t+1}(x)-C(x, \cdot)}{\epsilon})],
\end{align}
and the extrapolated version
\begin{align}
    \exp(-\frac{f_{t+1/2}}{\epsilon}) &=
     (1 - \eta) \exp(-\frac{f_{t}}{\epsilon}) 
     + \eta \EE_\beta[\epsilon \exp( \frac{g_t(y)-C(\cdot, y)}{\epsilon})], \\
     \exp(-\frac{g_{t+1/2}}{\epsilon}) &=
     (1 - \eta) \exp(-\frac{g_{t}}{\epsilon}) 
     + \eta \EE_\alpha[\epsilon \exp( \frac{f_t(x)-C(x, \cdot)}{\epsilon})], \\
     \exp(-\frac{f_{t+1}}{\epsilon}) &=
     \exp(-\frac{f_{t}}{\epsilon}) - \eta \exp(-\frac{g_{t + 1 / 2}}{\epsilon})
     + \eta \EE_\beta[\epsilon \exp( \frac{g_{t+1/2}(y)-C(\cdot, y)}{\epsilon})], \\
     \exp(-\frac{g_{t+1}}{\epsilon}) &=
     \exp(-\frac{g_{t}}{\epsilon}) - \eta \exp(-\frac{g_{t + 1 / 2}}{\epsilon})
     + \eta \EE_\alpha[\epsilon \exp( \frac{f_{t+1/2}(x)-C(x, \cdot)}{\epsilon})].
\end{align}
\paragraph{Computations.} In the simple simultaneous case, we can track $f_t$ in memory by the following representation
\begin{align}
    f_t(\cdot) &= - \epsilon \log \sum_{s=0}^t w_{t,s} \sum_{j=1}^n b_{s, j} 
    \exp\Big(g_{s-1}(y_{s,j}) - \frac{C(\cdot, y_{s, j})}{\epsilon}\Big) \\
    g_t(\cdot) &= - \epsilon \log \sum_{s=0}^t w_{t,s} \sum_{i=1}^n a_{s, i} 
    \exp\Big(f_{s-1}(x_{s, i}) - \frac{C(x_{s,i}, \cdot)}{\epsilon}\Big),
\end{align}
with $w_{t,s} = \eta (1-\eta)^{t-s}$ for $1 \leq s \leq t$, $w_{t,0} =
(1-\eta)^{t}$, and we set $g_{-1} = f_{-1} = 0$. The weights are a bit more
complex is $\eta$ depends on time.

The alternated version sets
\begin{equation}
    g_t(\cdot) = - \epsilon \log \sum_{s=0}^t w_{t,s} \sum_{i=1}^n a_{s, i} 
    \exp\Big(f_{s}(x_{s, i}) - \frac{C(x_{s,i}, \cdot)}{\epsilon}\Big),
\end{equation}

Setting $q_{t,s,i} = w_{t,s} b_{s, j} \exp(g_{s-1}(y_{s,
j}))$ and $p_{t,s,i} = w_{t,s} b_{s, j} \exp(f_{s-1}(x_{s, j})/ \epsilon)$, we can derive
simple update rules for $p$ and $q$:
\begin{equation}
    p_{t,t, i} = \eta b_{t,j} \exp(f_{t-1}(x_{t, j}),
    \qquad \foralls s < t,\quad p_{t,s, i} = (1- \eta) p_{t-1,s, i}
\end{equation}


\section{Analysis}

Bregman divergence associated to $\phi$ (désolé j'ai changé de notation).
\begin{equation}
    d_{\phi}(f_2|f_1) = \dotp{\alpha}{\exp(\frac{f_2-f_1}{\varepsilon})
     - 1 - \frac{f_2-f_1}{\varepsilon}}
      \geq \dotp{\alpha}{\big(\frac{f_2-f_1}{2 \varepsilon}\big)^2}
\end{equation}

For convergence of MD on $\min f(x)$ with mirror map $\phi$, we need to show, according to Gabriel, Jalal and Kelvin
\begin{equation}
    \mu d_\phi(x_2|x_1 )\leq d_f(x_2|x_1) \leq L d_\phi(x_2|x_1).
\end{equation}
Can we use that here ? Beware that we are in an alternated setting


\subsection{Sketch of proof}

See proof of Th2 in Ya Ping's paper.

\subsubsection{General proof}

By using the dual iteration and the three point property (normally holds by def of $D_{\alpha}$ and $D_{\beta}$):
\begin{align*}
\ps{\mu_t-\mu}{-\nabla_{\mu} \Ff(\mu_t,\nu_t)}&=\frac{1}{\eta}\ps{\mu_t-\mu}{\nabla_{\mu}w_{\alpha}(\mu_{t+1})-\nabla_{\mu}w_{\alpha}(\mu_t)}\\
&=\frac{1}{\eta}[D_{w_{\alpha}}(\mu,\mu_{t})-D_{w_{\alpha}}(\mu,\mu_{t+1})+D_{w_{\alpha}}(\mu_t,\mu_{t+1})]
\end{align*}
Suppose we can show (TO DO): 
\begin{align}\label{eq:bound_gradient}
D_{w_{\alpha}}(\mu_t,\mu_{t+1})\le \eta^2 M^2
\end{align}
Then we have:
\begin{align*}
\frac{1}{T}\sum_{t=1}^T \ps{\mu_t-\mu}{-\nabla_{\mu} \Ff(\mu_t,\nu_t)}&= \sum_{t=1}^T \frac{1}{\eta}[D_{w_{\alpha}}(\mu,\mu_{t})-D_{w_{\alpha}}(\mu,\mu_{t+1})+D_{w_{\alpha}}(\mu_t,\mu_{t+1})]\\
\le \frac{D_{w_{\alpha}}(\mu,\mu_1)}{\eta}+\eta M^2 T
\end{align*}
Similarly:
\begin{align*}
\frac{1}{T}\sum_{t=1}^T \ps{\nu_t-\nu}{-\nabla_{\nu} \Ff(\mu_t,\nu_t)}&
\le \frac{D_{w_{\beta}}(\mu,\mu_1)}{\eta}+\eta M^2 T
\end{align*}
Summing up the two previous equations and replacing $(\mu,\nu)$ by $(\mu*,\nu*)$, we get:
\begin{equation}
\frac{1}{T}\sum_{t=1}^T \ps{\mu_t-\mu*}{-\nabla_{\mu} \Ff(\mu_t,\nu_t)} + \ps{\nu_t-\nu*}{-\nabla_{\nu} \Ff(\mu_t,\nu_t)}\le \frac{D_0}{\eta}+2\eta M^2 T
\end{equation}
where $D_0=D_{w_{\alpha}}(\mu^*,\mu_1)+D_{w_{\beta}}(\nu^*,\nu_1)$.\\

\noindent Then, by optimality of $\mu^*$ and convexity of $\Ff$:
\begin{multline*}
\Ff(\mu_t,\nu_t)-\Ff(\mu^*,\nu^*)\le \Ff(\mu_t,\nu_t)-\Ff(\mu^*,\nu_t)
\le \ps{\mu^*-\mu_t}{\nabla_{\mu}\Ff(\mu_t,\nu_t)}= \ps{\mu_t-\mu^*}{-\nabla_{\mu}\Ff(\mu_t,\nu_t)}
\end{multline*}
Hence:
\begin{equation}
\frac{1}{T}\sum_{t=1}^T  
\Ff(\mu_t,\nu_t)-\Ff(\mu^*,\nu^*) \le \frac{D_0}{\eta}+2\eta^2 M^2 T
\end{equation}

\subsubsection{Tricky part}
Now let's try to prove Equation \ref{eq:bound_gradient}. 
What we need is 
\begin{itemize}
	\item $D_{w_{\alpha}}(\mu,\nu)=D_{w_{\alpha}^*}(\nabla_{\mu}w_{\alpha}(\mu), \nabla_{\mu}w_{\alpha}(\nu))$ (eq A.13 in Ya Ping's paper)
	\item  \textit{relative smoothness of $w_{\alpha}^*$ wrt $\|.\|_{\infty}$} (eq A.11 and A.12 in Ya Ping's paper)
\end{itemize}
 If it's true:
\begin{align*}
D_{w_{\alpha}}(\mu_t,\mu_{t+1}) = D_{w_{\alpha}^*}(\nabla_{\mu}w_{\alpha}(\mu_t), \nabla_{\mu}w_{\alpha}(\mu_{t+1}))\le \| \nabla_{\mu}w_{\alpha}(\mu)- \nabla_{\mu}w_{\alpha}(\nu)\|^2_{\infty}\\
=\| \exp(-\frac{f_{t+1}}{\epsilon})- \exp(-\frac{f_t}{\epsilon})\|^2_{\infty} = \eta^2 \| \nabla \Ff_{\mu}(\mu_t,\nu_t)\|^2_{\infty}
\end{align*}
and 
\begin{align*}
\|\nabla \Ff_{\mu}(\mu_t,\nu_t)\|^2_{\infty}\le ?
\end{align*}

WIP
\begin{equation}
    D_{w_{\alpha}}(\mu_t,\mu_{t+1}) \geq
    \Vert \log \frac{\mathrm d \mu_{t+1}}{\mathrm d \mu_{t}} \Vert_\alpha^2
\end{equation}

We can show
\begin{align}
    D_{\omega_\alpha}(\mu_t | \mu_{t+1}) = \eta^2
    \dotp{\alpha}{1 - \exp(\frac{f_t - \hat f_{t+1}}{\epsilon})},
    = \eta^2 (1 - \dotp{\alpha}{\nabla_\mu \Ff(\mu_t, \nu_t)})
    \\ \hat f_{t+1}(\cdot) 
    = - \varepsilon \log \int_y \exp(\frac{g_t(y) - C(\cdot, y)}{\varepsilon}) \mathrm d \beta(y).
\end{align}
Avec Sinkhorn sans bruit $f_t - \hat f_{t+1}$ va rester tranquille.

\section{Proof of convergence}

We want to solve
\begin{equation}
    \min_{\mu \in \Mm^+(\Xx), \nu \in \Mm^+(\Xx)} 
    F(\mu, \nu) \triangleq \KL(\alpha | \mu) + \KL(\beta | \nu) + \dotp{\mu \otimes \nu}{\exp(-C)}
\end{equation}

Let's write $x = (\mu, \nu)$  and $F(\mu, \nu) = F(x)$ the objective. We define the iterates $x_{t} = (\mu_t, \nu_t)$, $x_{t+1/2} = (\mu_{t+1}, \nu_t)$, 
$x_{t} = (\mu_{t+1}, \nu_{t+1})$. First note that we have
\begin{equation}
    D_{F(\mu, \cdot)} = D_{\omega_\alpha(\cdot)}\qquad D_{F(\cdot, \nu)} = D_{w_\beta(\cdot)},
\end{equation}
so that at every iteration, we perform a mirror step with a function that is both 1-relatively smooth and 1-relatively strongly convex.

Let $\nu$ be fixed, and let us define $F_\nu(\cdot) = F(\cdot, \nu)$. From the
smoothness of $F_\nu(\cdot)$ and from its convexity we have, for all 
$\mu_x, \mu_y, \mu_z \gg \alpha$,
\begin{align}
    F(\mu_x, \nu) &\leq F(\mu_y, \nu)
     + \dotp{\nabla_\mu F(\mu_y, \nu)}{\mu_x- \mu_y} + L D_{\omega_\alpha}(\mu_x, \mu_y), \\
    F(\mu_y, \nu) &\leq F(\mu_z, \nu) + \dotp{\nabla_\mu F(\mu_y, \nu)}{\mu_y - \mu_z}
\end{align}
Combining both, we obtain
\begin{align}
    F(\mu_x, \nu) &\leq F(\mu_z, \nu) + 
    \dotp{\nabla_\mu F(\mu_y, \nu)}{\mu_x - \mu_z} + L D_{\omega_\alpha}(\mu_x, \mu_y) \\
    \dotp{\nabla F(\mu_y, \nu)}{\mu_x - \mu_z} 
    &\geq F(\mu_x, \nu) - F(\mu_z, \nu) - L D_{\omega_\alpha}(\mu_x, \mu_y).
\end{align}
We now use the three point propery:
\begin{equation}
    D_{\omega_\alpha}(\mu_z, \mu_y) - D_{\omega_\alpha}(\mu_z, \mu_x) 
    - D_{\omega_\alpha}(\mu_x, \mu_y) 
    = \dotp{\nabla \omega_\alpha(\mu_x) - \nabla \omega_\alpha(\mu_y)}{\mu_z - \mu_x},
\end{equation}
replacing $\mu_y = \mu_{k}, \mu_x = \mu_{k+1}, \nu = \nu_k$, we obtain from the definition of the gradient update
\begin{align}
    D_{\omega_\alpha}(\mu_z, \mu_k) - D_{\omega_\alpha}(\mu_z, \mu_{k+1}) 
    - D_{\omega_\alpha}(\mu_{k+1}, \mu_k) &=
     \eta_k \dotp{\nabla_\mu F(\mu_k, \nu_k)}{\mu_{k+1} - \mu_z} 
     + \eta_k \dotp{\xi_k}{\mu_{k+1} - \mu_z} \\
    &\geq \eta_k (F(\mu_{k+1}, \nu_k) - F(\mu_z, \nu_k)))
     - L \eta_k D_{\omega_\alpha}   (\mu_{k+1},\mu_k) \\
     &+ \eta_k \dotp{\xi_k}{\mu_{k+1} - \mu_z}.
\end{align}
Hence, mimicking the derivation for $\nu$
\begin{align}
    \eta_k (F(\mu_{k+1},\nu_{k+1}) - F(\mu_{k+1}, \nu_z)) &\leq 
    D_{\omega_\beta}(\nu_z, \nu_k) - D_{\omega_\beta}(\nu_z, \nu_{k+1}) 
    - (1 - \eta_k L) D_{\omega_\beta}(\nu_{k+1}, \nu_k). \\
    \eta_k (F(\mu_{k+1},\nu_k) - F(\mu_z, \nu_k)) &\leq 
    D_{\omega_\alpha}(\mu_z, \mu_k) - D_{\omega_\alpha}(\mu_z, \mu_{k+1}) 
    - (1 - \eta_k L) D_{\omega_\alpha}(\mu_{k+1}, \mu_k)
\end{align}
Setting $\mu_z = \mu_{k}$, $\nu_z = \nu_k$, we obtain a descent lemma.
\begin{equation}
    F(\mu_{k+1}, \nu_{k+1}) \leq F(\mu_{k+1}, \nu_{k}) \leq F(\mu_{k}, \nu_{k}),
\end{equation}
which ensures almost sure convergence of $F(\mu_k, \nu_k)$ to $F^\star$ using constant step-sizes (gradient is zero for $k \to \infty$).

We further have, replacing $\mu_z = \mu^\star, \nu_z = \nu^\star$
%
\begin{equation}
    F(\mu_{k+1}, \nu_{k+1}) - F^\star
    - \frac{
        \sum_{k=1}^k \eta_k (F(\mu_{k+1}, \nu^\star)
    +F(\mu^\star, \nu_k) - 2 F^\star))
    }
    {2 \sum_{k=1}^k \eta_k}
    \leq \frac{
    D_{\omega_\alpha}(\mu^\star, \mu_1)
    + D_{\omega_\beta}(\nu^\star, \nu_1)
    }{2 \sum_{k=1}^K \eta_k}
\end{equation}
Now note that
\begin{equation}
    (F(\mu_{k+1}, \nu^\star)
    +F(\mu^\star, \nu_k) - 2 F^\star) =
     D_{\omega_\alpha}(T(g_k, \beta), f^\star)
     + D_{\omega_\beta}(T(f_{k+1}, \alpha), g^\star)
\end{equation}
We may show the contractance of the soft c-tranform for the following metric
\begin{equation}
    \phi(f, g) = \min_{f^\star, g^\star \in \Ss} 
    D_{\omega_\alpha}(f, f^\star)
    +
    D_{\omega_\beta}(g, g^\star).
\end{equation}
Namely, if 
\begin{equation}
    \phi(T(f,\alpha), T(g,\beta))
    \leq \phi(f, g).
\end{equation}
It is then easy to show (convexity argument) that
\begin{equation}
    \phi(f_{t+1}, g_{t+1}) \leq
    (1-\eta) 
    \phi(f_t, g_t)
    + \eta \phi(T(f_t,\alpha), T(g_t,\beta))
\end{equation}
What can be shown is unfortunately
\begin{equation}
    D_{\omega_\alpha}(T(g,\beta), f^\star) +
    D_{\omega_\beta}(T(f,\alpha), g^\star). \leq
    D_{\omega_\alpha}(f^\star, f)
    +
    D_{\omega_\beta}(g^\star, g).
\end{equation}



\paragraph{Simultaneous gradient descent.} We have

\begin{align}
    \eta_k (F(\mu_k,\nu_{k+1}) - F(\mu_k, \nu_z)) &\leq 
    D_{\omega_\beta}(\nu_z, \nu_k) - D_{\omega_\beta}(\nu_z, \nu_{k+1}) 
    - (1 - \eta_k L) D_{\omega_\beta}(\nu_{k+1}, \nu_k). \\
    \eta_k (F(\mu_{k+1},\nu_k) - F(\mu_z, \nu_k)) &\leq 
    D_{\omega_\alpha}(\mu_z, \mu_k) - D_{\omega_\alpha}(\mu_z, \mu_{k+1}) 
    - (1 - \eta_k L) D_{\omega_\alpha}(\mu_{k+1}, \mu_k)
\end{align}
Therefore
\begin{align}
    \eta_k \big(F(\mu_k,\nu_{k+1}) + F(\mu_{k+1},\nu_k) - 2 F(\mu_z, \nu_z) \\
     - ( F(\mu_k, \nu_z) + F(\mu_z, \nu_k) - 2 F(\mu_z, \nu_z)\big)
      &\leq 
    D_{\omega_\beta}(\nu_z, \nu_k) + D_{\omega_\alpha}(\mu_z, \mu_k) \\
    &\phantom{=}- \big(D_{\omega_\alpha}(\mu_z, \mu_{k+1})
     + D_{\omega_\beta}(\nu_z, \nu_{k+1})\big) \\
     &\phantom{=}
    - (1 - \eta_k) 
    \big(D_{\omega_\beta}(\nu_{k+1}, \nu_k) + D_{\omega_\alpha}(\mu_{k+1}, \mu_k)\big)
\end{align}
Let's observe that, for all $(\mu^\star, \nu^\star) \in \Ss$, $(\mu,\nu)$
\begin{align}
    D_{\omega_\beta}
    (\nu^\star, \nu) + D_{\omega_\alpha}(\mu^\star, \mu)
    &= \KL(\alpha|\mu) + \KL(\beta|\nu) 
    + \big(\dotp{\mu \otimes\nu^\star}{\exp(-C)}
     +\dotp{\mu^\star \otimes\nu}{\exp(-C)} - 2\big) - F(\mu^\star, \nu^\star) \\
     &= F(\mu, \nu^\star) + F(\mu^\star, \nu) - 2 F(\mu^\star, \nu^\star)
\end{align}
We take $(\mu_z,\nu_z) = (\mu^\star,\nu^\star)$, that optimizes
\begin{align}
    G(\mu_k, \nu_k) &\triangleq \min_{\mu^\star, \nu^\star} D_{\omega_\beta}
    (\nu^\star, \nu_k) + D_{\omega_\alpha}(\mu^\star, \mu_k) \\
    &= \KL(\alpha|\mu) + \KL(\beta|\nu) 
    + 2 \big( \sqrt{\dotp{\mu^\star \otimes \nu}{\exp(-C)} 
    \dotp{\mu \otimes \nu^\star}{\exp(-C)}} - 1) - 
    F^\star
\end{align}
Then
\begin{align}
    \eta_k \big(F(\mu_k,\nu_{k+1}) + F(\mu_{k+1},\nu_k) - 2 F^\star)
     &\leq 
    (1 + \eta_k) G(\mu_k, \nu_k) - G(\mu_{k+1}, \nu_{k+1}) \\
    &\phantom{=}
    - (1 - \eta_k) 
    \big(D_{\omega_\beta}(\nu_{k+1}, \nu_k) + D_{\omega_\alpha}(\mu_{k+1}, \mu_k)\big)    
\end{align}
Note that, using $\sqrt{ab} \geq \frac{a + b}{2}$ 
\begin{align}
    F(\mu_k,\nu_{k+1}) + F(\mu_{k+1},\nu_k) - G(\mu_k, \nu_k) - 2 F^\star
    &\geq \KL(\alpha|\mu_{k+1}) + \KL(\beta|\nu_{k+1}) - F^\star
        + 2 u_k,
\end{align}
where 
\begin{align}
    u_k &\triangleq
    \frac{
        \dotp{\mu_k \otimes (\nu_{k+1} - \nu^\star)}{\exp(-C)}
        + \dotp{(\mu_{k+1} - \mu^\star)\otimes \nu_k}{\exp(-C)}
        }{2} \\
\end{align}
Now let's observe that the harmonic mean is always smaller than the arithmetic mean:
\begin{equation}
    \frac{\d \mu_{k+1}}{\d \alpha}
     = \frac{1}{(1- \eta_k) \frac{1}{\frac{\d \mu_{k}}{\d \alpha}}
     + \eta_k \frac{1}{\frac{\d \alpha \exp(T(g_k, \beta))}{\d \alpha}}}
     \leq (1-\eta_k) \frac{\d \mu_{k}}{\d \alpha}
     + \eta_k \frac{\d \alpha \exp(T(g_k, \beta))}{\d \alpha},
\end{equation}
hence
\begin{align}
    \mu_{k+1} &\leq (1 -\eta_k) \mu_k + \eta_k T(\nu_k, \beta) \\
    \nu_{k+1} &\leq (1 -\eta_k) \nu_k + \eta_k T(\mu_k, \beta)
\end{align}
Therefore, from the definition of the $c$-transform
\begin{align}
    u_{k+1} \leq (1 - \eta_k) u_k
\end{align}
Finally
\begin{equation}
    \eta_k (\KL(\alpha|\mu_{k+1}) + \KL(\beta|\nu_{k+1}) - F^\star) \leq 
    G(\mu_k, \nu_k) - G(\mu_{k+1},\nu_{k+1}) - 2 \eta_k \mu_k,
\end{equation}
hence convergence !
% Similarly,
% \begin{align}
%     (v_{k+1} + 1)^2 &\leq  (1-\eta_k) v_k + \eta_k^2 
%     \sqrt{
%             \dotp{\mu^\star \otimes T(\mu_k,\alpha)}{\exp(-C)}
%             \dotp{T(\nu_k,\beta) \otimes \nu^\star}{\exp(-C)}
%             } \\
%         &+ \eta_k (1-\eta_k) \big(
%             \sqrt{
%         \dotp{T(\nu^\star,\beta) \otimes T(\mu_k,\beta)}{\exp(-C)}
%         \dotp{\mu_k \otimes \nu^\star}{\exp(-C)} 
%             }\\ 
%         &+ \sqrt{
%             \dotp{\mu^\star \otimes \nu_k}{\exp(-C)}
%             \dotp{T(\nu_k,\beta) \otimes T(\mu^\star, \alpha)}{\exp(-C)}
%         } - 1
%         ) \\
%         &= (1 - \eta_k(1 - \sqrt{\rho})) (v_k + 1)^2,
% \end{align}
% as we know that 
% \begin{equation}
%     \dotp{\alpha \otimes \beta}{\exp(T(f,\alpha) \oplus T(g,\beta) - C)} \leq
%     \rho 
%     \dotp{\alpha \otimes \beta}{f \oplus g - C)}
% \end{equation}

\section{Proofs}

\begin{proof}
Remark that 
\begin{align}
    f_{t+1} &=  - \log (\exp(-f_t) (1 - \eta_t) + \eta_t \exp(-T(g_t, \beta))) \\ 
    g_{t+1} &=  - \log (\exp(-g_t) (1 - \eta_t) + \eta_t \exp(-T(f_{t+1}, \alpha)))
\end{align}
Let $(f^\star, g^\star)$ be a coupl of solution. There exists $x \in \Xx$ such that $\Vert
f_{t+1} - f^\star \Vert_{\var} = |f_{t+1}(x) - f^\star(x)|$. For this~$x$, using
the convexity of $- \log(x)$ (more or less the mirror map),
\begin{align}
    \Vert f_{t+1} - f^\star \Vert_{\var}
    &=
     |- \log\big((1 - \eta_t) \exp(f^\star -f_t(x)) 
     + \eta_t \exp(f^\star-T(g_t, \beta)(x)\big) |  \\
    &\leq (1 - \eta_t) | f_t(x) - f^\star(x)| + \eta_t | T(g_t,\beta)(x) - f^\star(x)| \\
    &\leq (1 - \eta_t) \Vert f_t - f^\star \Vert_{\var} + \eta_t
    \Vert T(g_t,\beta) - T(g^\star, \beta) \Vert_{\var} \\
    &\leq (1 - \eta_t) \Vert f_t - f^\star \Vert_{\var}
     + \eta_t \tappa \Vert g_t - g^\star \Vert_{\var}
\end{align}
Similarly
\begin{align}
    \Vert g_{t+1} - f^\star \Vert_{\var} \leq
    (1 - \eta_t) \Vert g_t - g^\star \Vert_{\var} +
     \eta_t \tappa \Vert f_{t+1} - f^\star \Vert_{\var}
\end{align}
Therefore
\begin{align}
    \Vert g_{t+1} - g^\star \Vert_{\var} + \Vert f_{t+1} - f^\star \Vert_{\var} \leq
    (1 - \eta_t + \tappa^2 \eta_t^2)) ( \Vert f_t - f^\star \Vert_{\var} 
     + \Vert g_t - g^\star \Vert_{\var} ),
\end{align}

\subsection{An adapted mirror descent convergence proof in the non-noisy case}


We want to solve
\begin{equation}
    \min_{\mu \in \Mm^+(\Xx), \nu \in \Mm^+(\Xx)} 
    F(\mu, \nu) \triangleq \KL(\alpha | \mu) + \KL(\beta | \nu) + \dotp{\mu \otimes \nu}{\exp(-C)}
\end{equation}
First note that we have
\begin{equation}
    D_{F(\mu, \cdot)} = D_{\omega_\alpha(\cdot)}\qquad D_{F(\cdot, \nu)} = D_{w_\beta(\cdot)},
\end{equation}
so that at every iteration, we perform a mirror step with a function that is 1-relatively smooth.

Let $\nu$ be fixed, and let us define $F_\nu(\cdot) = F(\cdot, \nu)$. From the relative
smoothness of $F_\nu(\cdot)$ and from its convexity we have, for all 
$\mu_x, \mu_y, \mu_z \gg \alpha$,
\begin{align}
    F(\mu_x, \nu) &\leq F(\mu_y, \nu)
     + \dotp{\nabla_\mu F(\mu_y, \nu)}{\mu_x- \mu_y} + D_{\omega_\alpha}(\mu_x, \mu_y), \\
    F(\mu_y, \nu) &\leq F(\mu_z, \nu) + \dotp{\nabla_\mu F(\mu_y, \nu)}{\mu_y - \mu_z}
\end{align}
Combining both, we obtain
\begin{align}
    F(\mu_x, \nu) &\leq F(\mu_z, \nu) + 
    \dotp{\nabla_\mu F(\mu_y, \nu)}{\mu_x - \mu_z} + D_{\omega_\alpha}(\mu_x, \mu_y) \\
    \dotp{\nabla F(\mu_y, \nu)}{\mu_x - \mu_z} 
    &\geq F(\mu_x, \nu) - F(\mu_z, \nu) - D_{\omega_\alpha}(\mu_x, \mu_y).
\end{align}
We now use the three point propery:
\begin{equation}
    D_{\omega_\alpha}(\mu_z, \mu_y) - D_{\omega_\alpha}(\mu_z, \mu_x) 
    - D_{\omega_\alpha}(\mu_x, \mu_y) 
    = \dotp{\nabla \omega_\alpha(\mu_x) - \nabla \omega_\alpha(\mu_y)}{\mu_z - \mu_x},
\end{equation}
replacing $\mu_y = \mu_{k}, \mu_x = \mu_{k+1}, \nu = \nu_k$, we obtain
\begin{align}
    D_{\omega_\alpha}(\mu_z, \mu_k) - D_{\omega_\alpha}(\mu_z, \mu_{k+1}) 
    - D_{\omega_\alpha}(\mu_{k+1}, \mu_k) &=
     \eta_k \dotp{\nabla_\mu F(\mu_k, \nu_k)}{\mu_{k+1} - \mu_z} \\
    &\geq \eta_k (F(\mu_{k+1}, \nu_k) - F(\mu_z, \nu_k)))
     - \eta_k D_{\omega_\alpha}   (\mu_{k+1},\mu_k).
\end{align}
Hence, mimicking the derivation for $\nu$,
\begin{align}\label{eq:mirror_ineq}
    \eta_k (F(\mu_{k+1},\nu_k) - F(\mu_z, \nu_k)) &\leq 
    D_{\omega_\alpha}(\mu_z, \mu_k) - D_{\omega_\alpha}(\mu_z, \mu_{k+1}) 
    - (1 - \eta_k) D_{\omega_\alpha}(\mu_{k+1}, \mu_k) \\
    \eta_k (F(\mu_{k+1},\nu_{k+1}) - F(\mu_{k+1}, \nu_z)) &\leq 
    D_{\omega_\beta}(\nu_z, \nu_k) - D_{\omega_\beta}(\nu_z, \nu_{k+1}) 
    - (1 - \eta_k) D_{\omega_\beta}(\nu_{k+1}, \nu_k)
\end{align}
Setting $\mu_z = \mu_{k}$, $\nu_z = \nu_k$, we obtain a descent lemma.
\begin{equation}
    F(\mu_{k+1}, \nu_{k+1}) \leq F(\mu_{k+1}, \nu_{k}) \leq F(\mu_{k}, \nu_{k}),
\end{equation}
Summing both equations of \eqref{eq:mirror_ineq}, we obtain
\begin{align}
    &\eta_k (F(\mu_{k+1},\nu_k) + F(\mu_{k+1},\nu_{k+1})
    - (F(\mu_z, \nu_k) + F(\mu_{k+1}, \nu_z))) \\ 
    &\leq 
    D_{\omega_\alpha}(\mu_z, \mu_k)
    + D_{\omega_\beta}(\nu_z, \nu_k)
    - (D_{\omega_\alpha}(\mu_z, \mu_{k+1}) 
     + D_{\omega_\beta}(\nu_z, \nu_{k+1}))
\end{align}
For $k \in \NN$, we set $(\mu_z, \nu_z) = (\mu^\star_k, \nu^\star_k)$, such that
\begin{align}
    (\mu^\star_k, \nu^\star_k) &\triangleq \argmin_{\mu^\star, \nu^\star} D_{\omega_\beta}
    (\nu^\star, \nu_k) + D_{\omega_\alpha}(\mu^\star, \mu_k),
\end{align}
and define
\begin{align}
    G(\mu_k, \nu_k) &\triangleq \min_{\mu^\star, \nu^\star} 
    D_{\omega_\beta}
    (\nu^\star, \nu_k) + D_{\omega_\alpha}(\mu^\star, \mu_k) \\
    &= \KL(\alpha|\mu_k) + \KL(\beta|\nu_k) 
    + 2 \big( \sqrt{\dotp{\mu^\star \otimes \nu}{\exp(-C)} 
    \dotp{\mu \otimes \nu^\star}{\exp(-C)}} - 1) - F^\star. \\
    % &= F(\mu_k^\star, \nu_k) + F(\mu_k, \nu_k^\star) - 2F^\star
\end{align}
We obtain
\begin{equation}
    \eta_k (
        (F(\mu_{k+1}, \nu_{k+1}) - F^\star
        \leq G(\mu_k, \nu_{k}) - G(\mu_{k+1}, \nu_{k+1}) + \eta_k w_k + \eta_k z_k,
\end{equation}
where
\begin{align}
    z_k &= 1 - \dotp{\mu_{k+1} \otimes \nu_k}{\exp(-C)} \\
    w_k &= \dotp{\mu_k^\star \otimes \nu_k}{\exp(-C)}
    + \dotp{\mu_{k+1} \otimes \nu_k^\star}{\exp(-C)} - 2\\
    &=\left(
    \dotp{\mu_{k+1} \otimes \nu^\star}{\exp(-C)}
    \dotp{\mu^\star \otimes \nu_k}{\exp(-C)}
    \right)^{1/2}
    \left(
        \left(\frac{
            \dotp{\mu_k \otimes \nu^\star}{\exp(-C)}
        }
        {
            \dotp{\mu_{k+1} \otimes \nu^\star}{\exp(-C)}
        }\right)^{1/2}
        + 
        \left(\frac{
            \dotp{\mu_{k+1} \otimes \nu^\star}{\exp(-C)}
        }
        {
            \dotp{\mu_k \otimes \nu^\star}{\exp(-C)}
        }
        \right)^{1/2}
    \right) - 2.
\end{align}
The last term is quite ugly, due to the alternated nature of the algorithm.

\paragraph{Simultaenous updates.}  In the non alternated version:

\begin{align}
    &\eta_k (F(\mu_{k+1},\nu_k) + F(\mu_{k+1},\nu_k)
    - (F(\mu_z, \nu_k) + F(\mu_k, \nu_z))) \\ 
    &\leq 
    D_{\omega_\alpha}(\mu_z, \mu_k)
    + D_{\omega_\beta}(\nu_z, \nu_k)
    - (D_{\omega_\alpha}(\mu_z, \mu_{k+1}) 
     + D_{\omega_\beta}(\nu_z, \nu_{k+1}))
\end{align}


\printbibliography

\end{document}
