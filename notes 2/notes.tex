\documentclass[a4paper, 10pt]{article}
\input{preamble.tex}

\addbibresource{biblio.bib}

\begin{document}

\section{An online expectation minimization algorithm}

Define $\mu = \alpha \exp(f)$, $\nu = \beta \exp(g)$, $x = (\mu, \nu)$. We will change variables without warning in the following.
Define the Bregman divergence
\begin{align}
    D_{\alpha}(\mu, \mu_0) &= \dotp{\alpha}{\exp(f_0 - f) - 1 - (f_0 - f)} \\
    D_{\beta}(\nu, \nu_0) &= \dotp{\beta}{\exp(g_0 - g) - 1 - (g_0 - g)} \\
    D_{\alpha, \beta}(x, x_0) &= D_{\alpha}(\mu, \mu_0) + D_{\beta}(\nu, \nu_0)
\end{align}
We want to solve the objective
\begin{equation}
    \min_x \Ff(x) \triangleq \KL(\alpha, \mu) + \KL(\beta, \nu) + \dotp{\mu \otimes \nu}{\exp(-C)} - 1
\end{equation}
Define the prox objective
\begin{align}
    \Ll(x, x_t) &= 2 \Ff(x_t) + \dotp{\nabla \Ff(x_t)}{x - x_t} + D_{\alpha,\beta}(x, x_t) \\
    &= \EE_{\hat \alpha \sim \alpha, \hat \beta \sim \alpha}
    \Big[2 F(x_t) + \dotp{\nabla \Ff(x_t)}{x - x_t} + D_{\hat \alpha,\hat \beta}(x, x_t) \Big]
\end{align}
The Sinkhorn iterations then rewrites as
\begin{equation}
    x_{t+1} = \argmin_x \EE_{\hat \alpha, \hat \beta} \Ll_{\hat \alpha, \hat \beta}(x, x_t)
\end{equation}
and online Sinkhorn

\begin{equation}
    x_{t+1} = (1 - \eta_t) x_t + \eta_t \argmin_x \Ll_{\hat \alpha_t, \hat \beta_t}(x, x_t)
\end{equation}
Probably useless ?

\section{Variable mirror descent point of view}

Consider the objective
\begin{equation}
    \max_{f, g} \Ff(f, g) = \dotp{\alpha}{f} + \dotp{g, \beta} -
     \dotp{\alpha \otimes \beta}{\exp(f \oplus g - C)} + 1
\end{equation}
The gradient reads
\begin{equation}
    \nabla \Ff(f, g) = \Big(\alpha\big(1 - \exp(f - T_\beta(g))\big), \beta\big(1 - \exp(g - T_\alpha(f))\big)\Big)
     \in \Mm^+(\Xx^2)
\end{equation}
Using the local Bregman divergence
\begin{equation}
    \omega_t(f, g) = \dotp{\alpha}{\exp(f_t - f)} + \dotp{\beta}{\exp(g_t - g)},
\end{equation}
online Sinkhorn iterations rewrites as
\begin{equation}
    \nabla \omega_t(f_{t+1}, g_{t+1}) = \nabla \omega_t(f_t, g_t) + \eta_t \tilde \nabla \Ff(f_t, g_t),
\end{equation}
where 
\begin{equation}
    \tilde \nabla \Ff(f, g) = \Big(\hat \alpha_t \big(1 - \exp(f - T_\beta(g))\big), 
    \hat \beta_t \big(1 - \exp(g - T_\alpha(f))\big)\Big)
    \in \Mm^+(\Xx^2)
\end{equation}
is an unbiased estimate of $\nabla \Ff(f, g)$.

\section{An EM point of view}

\begin{align}
    f_t, g_t = \argmax_{f, g} Q_t^\star((f, g), (f_t, g_t)) 
    &\triangleq \EE_{Y \sim \beta} \left[ \EE_{X \sim \alpha} \left[
     f(X) - e^{f(X) + g_t(Y) - C(X, Y)} \right] \right] \\
     &+
     \EE_{X \sim \alpha} \left[ \EE_{Y \sim \beta} \left[
     g(Y) - e^{f_t(X) + g(Y) - C(X, Y)} \right] \right]
\end{align}
We now define the approximate functions

\begin{align}
    Q_t((f, g), (f_t, g_t)) &= \EE_{Y \sim \hat \beta_t} \left[ \EE_{X \sim \alpha} \left[
        f(X) - e^{f(X) + g_t(Y) - C(X, Y)} \right] \right] \\
        &+
        \EE_{X \sim \hat \alpha_t} \left[ \EE_{Y \sim \beta} \left[
        g(Y) - e^{f_t(X) + g(Y) - C(X, Y)} \right] \right] \\
        &= \EE_{X \sim \alpha} [f(X)] + \EE_{X \sim \alpha} \left[ \sum_{i=n_t}^{n_{t+1}} 
        b_i e^{f(X) + g_t(y_i) - C(X, y_i)} \right] \\
        &+ \EE_{Y \sim \beta} [g(Y)] + \EE_{Y \sim \beta} \left[ \sum_{i=n_t}^{n_{t+1}} 
        a_i e^{g(Y) + f_t(x_i) - C(x_i, Y)} \right]
\end{align}
Running the iterations
\begin{equation}
    f_t, g_t = \argmax_{f,g} Q_t((f, g), (f_t, g_t))
\end{equation}
amounts to set
\begin{equation}
    f_t(\cdot) = - \log \sum_{i=n_t}^{n_{t+1}} b_i e^{g_t(y_i) - C(\cdot, y_i)} \quad
    g_t(\cdot) = - \log \sum_{i=n_t}^{n_{t+1}} a_i e^{f_t(x_i) - C(x_i, \cdot)},
\end{equation}
which is the randomized Sinkhorn algorithm. Setting
\begin{equation}
    \bar Q_{t+1} = (1 - \eta_t) \bar Q_{t} + \eta_t Q_{t}
\end{equation}
and running the iterations
\begin{equation}
    f_t, g_t = \argmin_{f,g} \bar Q_t((f, g), (f_t, g_t))
\end{equation}
gives online Sinkhorn:
\begin{equation}
    f_t(\cdot) = - \log \sum_{i=1}^{n_{t+1}} e^{q_i - C(\cdot, y_i)} \quad
    g_t(\cdot) = - \log \sum_{i=1}^{n_{t+1}} e^{p_i - C(x_i, \cdot)},
\end{equation}
with the update rule on $q_i, p_i$ as : see paper.
Every function $Q_t$ is parametrized by $(p_i, q_i, x_i, y_i)_{i=(n_t,
 n_{t+1}]}$, and $\bar Q_t$ by $(p_i, q_i, x_i, y_i)_{i=(0, n_{t+1}]}$. Thus the
 parametrization of $f_t, g_t$ is encoded using an argmax trick, and we recover the structure of a stochastic expectation-maximization algorithm (less the probabilistic point of view).


\printbibliography

\end{document}
