%!TEX root = article.tex


\section{Convergence analysis}

We give three kind of convergence analysis: (i) a stationary distribution convergence property for the random Sinkhorn
algorithm ; (ii) a global convergence property for the online Sinkhorn algorithm without noise ; (iii) a high-probability convergence result for the full online Sinkhorn algorithm.

%%%
\paragraph{Randomized Sinkhorn.}

We first state a result concerning the randomized Sinkhorn algorithm~\eqref{eq:updates}, which corresponds to
\autoref{alg:online_sinkhorn} with step-size $\eta_t = 1$.

\begin{proposition}\label{prop:markov}
    The random Sinkhorn algorithm \eqref{eq:updates} yields a time-homogeneous
    Markov chain ${(f_t, g_t)}_t$ which is $(\hat \alpha_s, \hat \beta_s)_{s \leq
    t}$ measurable, and weak-star converges toward a stationary distribution
    $(F_\infty, G_\infty) \in \Pp(\Cc(\Xx)^2)$ independent of the initialization
    point $(f_0, g_0)$.
\end{proposition}

This result follows from \citet{diaconis_iterated} convergence theorem on
iterated random functions which are contracting on average. We simply use the
fact that $\Ctrans{\cdot}{\hat \beta}$ and $\Ctrans{\cdot}{\hat \alpha}$ are
\textit{always} contracting, independent of the distributions $\hat \alpha$ and
$\hat \beta$, for the variational norm $\Vert \cdot \Vert_{\text{var}}$.

Note that using the law of large number for Markov chains
\citep{breiman_strong_1960}, the out-of-loop averages $\exp(-\bar f_t)$ for
converge to $\EE[\exp(-F_\infty)] \in \Cc(\Xx)$ for $\gamma_t = \frac{1}{t}$. This expectation verifies the following fixed point equations
\begin{align}
    \EE[\exp(-F_\infty)] &=
     \dotp{\beta}{\EE[\exp(G_\infty)] \exp(-C)} \\
    \EE[\exp(-G_\infty)] &=
     \dotp{\alpha}{\EE[\exp(F_\infty)] \exp(-C)}.
\end{align}
This fixed point equations are close to the Sinkhorn fixed point equations, and converges to them 
get closer as $\varepsilon$ increases, since $\varepsilon \EE[\exp(\pm F_\infty /
\varepsilon)] \to \EE[F_\infty]$ as $\varepsilon \to \infty$. Running the random
Sinkhorn algorithm with out-of-loop averaging fails to provide exactly the dual solution, but 
however defines an approximate solution of the original problem whose accuracy depends on $\epsilon$. 
%
We leave the quantification of this approximation for future work.

%%%
\paragraph{Noise-free online Sinkhorn.}

Variance reduction is therefore necessary, to ensure that the limit stationary
distribution is deterministic. The following proposition shows that the modified "slowed-down" online Sinkhorn algorithm converges in the absence of noise.

\begin{proposition}\label{eq:deterministic}
    We suppose that $\hat \alpha_t = \alpha$, $\hat \beta_t = \beta$ for all
    $t$. Then the updates \eqref{eq:updates} yields a sequence $(f_t, g_t)_t$ such
    that 
    \begin{gather}
        \Vert f_t - f^\star \Vert_{\text{var}} 
        + \Vert g_t - g^\star \Vert_{\text{var}} \to 0 \\
        \frac{1}{2} \dotp{\alpha}{f_t + \Ctrans{g_t}{\alpha}} + \dotp{\beta}{g_t + \Ctrans{f_t}{\beta}} 
         \to \Ww(\alpha, \beta).
    \end{gather}
\end{proposition}
Note that, due to the fact that we perform simultaneous updates, we only obtain
the convergence of $f_t \to f^\star + A$, and $g_t \to g^\star$, where $f^\star$
and $g^\star$ are solutions of \eqref{eq:wass} and $A$ is a constant depending
on initialization. This is only a small caveat, as we can average the potentials
and their soft $C$-transform as in \eqref{eq-dist-est} to remove the offset $A$.
This is not necessary when using the Sinkhorn distance as a loss for training
purposes, e.g. for generative modeling or barycenter estimation as in
\citet{staib2017parallel}. Backpropagation through the Sinkhorn distance indeed
relies only on the gradients of the potentials $\nabla_x f^\star(\cdot)$,
$\nabla_y g^\star(\cdot)$ \citep[e.g.][]{cuturi2018semidual}.
%%%
\paragraph{Online Sinkhorn.}

Finally, we state a result on the complete online Sinkhorn algorithm, which converges with high probability.
\begin{proposition}
    Assume that $\Vert f_0 - f^\star \Vert_{\text{var}} \leq 1$ and $\Vert g_0 -
    g^\star \Vert_{\text{var}} \leq 1$, $\sum_t \eta_t = \infty$ and $\sum_t
    \eta_t^2 < \infty$ and fix a level of confidence $\delta$. Then, with
    probability $1- \delta$, provided that $\eta_t$ is small enough,
    \begin{gather}
        \Vert f_t - f^\star \Vert_{\text{var}} + \Vert g_t - 
        g^\star \Vert_{\text{var}} \to 0 \\
        \Ww_t =\frac{1}{2} \dotp{\alpha}{f_t + \Ctrans{g_t}{\alpha}} + \dotp{\beta}{g_t + \Ctrans{f_t}{\beta}} 
        \to \Ww(\alpha, \beta).
    \end{gather}
\end{proposition}
This result relies on Theorem 5.2 from~\citet{zhou2017convergence}, that establish convergence with
high probability of stochastic mirror descent applied to non-convex but locally coherent objectives. In particular, the proof of this results does not rely on the finite dimension of the ambiant space.

