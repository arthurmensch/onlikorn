\section{Analysis}

We state a stationary distribution convergence property for the random Sinkhorn
algorithm, a global convergence property for the online Sinkhorn algorithm
without noise, and a high-probability convergence result for the true online
Sinkhorn algorithm.

We first state a simple result concerning the random Sinkhorn algorithm, i.e.
\autoref{alg:online_sinkhorn} with step-size $\eta_t = 1$.

\begin{proposition}\label{prop:markov}
    The random Sinkhorn algorithm \eqref{eq:updates} yields a time-homogeneous
    Markov chain ${(f_t, g_t)}_t$ that is $(\hat \alpha_s, \hat \beta_s)_{s \leq
    t}$ measurable, and weak-star converges toward a stationary distribution
    $(F_\infty, G_\infty) \in \Pp(\Cc(X)^2)$ independent of the initialisation
    point $(f_0, g_0)$.
\end{proposition}

This is a simple consequence of \citep{diaconis_iterated} convergence theorem on
iterated random function that are contracting on average. It uses the fact that
$T(\cdot,\hat \beta)$ and $T(\cdot,\hat \alpha)$ are \textit{always}
contracting, independent of the distributions $\hat \alpha$ and $\hat \beta$.

Using the law of large number for Markov chains, the out-of-loop averages
$\exp(-\bar f_t), \exp(-\bar f_t)$ converges to $\EE[\exp(-F_\infty)] \in
\Cc(\Xx)$, that verifies the modified fixed point equation
\begin{align}
    \EE[\exp(-F_\infty)] &=
     \dotp{\beta}{\EE[\exp(G_\infty)] \exp(-C)} \\
    \EE[\exp(-G_\infty)] &=
     \dotp{\alpha}{\EE[\exp(F_\infty)] \exp(-C)}.
\end{align}
The later inequality is close to the Sinkhorn optimality conditions, and will
get closer as $\varepsilon$ increases, as $\varepsilon \EE[\exp(\pm F_\infty /
\varepsilon)] \to \EE[F_\infty]$ as $\varepsilon \to \infty$. Running the random
Sinkhorn algorithm with out-of-loop averaging will therefore converge towards an
approximate solution of the original problem. We leave the quantification of the
approximation for future work.

Variance reduction is therefore necessary, to ensure that the limit stationary
distribution is a Dirac, or is at least supported on a discrete set of limit
potentials. In the following proposition, we show that the modified online Sinkhorn algorithm converges in the absence of noise

\begin{proposition}\label{eq:deterministic}
    We suppose that $\hat \alpha_t = \alpha$, $\hat \beta_t = \beta$ for all
    $t$. Then the updates \eqref{eq:updates} yields a sequence $(f_t, g_t)$ such
    that 
    \begin{gather}
        \Vert f_t - f^\star \Vert_{\text{var}} 
        + \Vert g_t - g^\star \Vert_{\text{var}} \to 0 \\
        \frac{1}{2} \dotp{\alpha}{f_t + T(g_t, \alpha)} + \dotp{\beta}{g_t + T(f_t, \beta)} 
         \to \Ww(\alpha, \beta).
    \end{gather}
\end{proposition}
Notice that, due to the fact that we perform simultaneous updates and slow them
down, we only obtain the convergence of $f_t \to f^\star + A$, and $g_t \to
g^\star$, where $f^\star$ and $g^\star$ are solutions of \eqref{eq:wass} and $A$
is a constant depending on initialization. This is only a small caveat, as we
can average the potentials and their soft $C$-transform to remove the offset
$C$. When estimating the spatial derivative of $f^\star$ for training purposes, this is not necessary.

Finally, we state a result on the complete online Sinkhorn algorithm, that
converges with high probability.
% 
\begin{proposition}
    Assume that $\Vert f_0 - f^\star \Vert_{\text{var}} < 1$ and $\Vert f_0 -
    f^\star \Vert_{\text{var}} < 1$, $\sum_t \eta_t = \infty$ and $\sum_t
    \eta_t^2 < \infty$. Then, with a probability $p$ that can be as close to $1$
    as possible, decreasing the step-sizes,
    \begin{gather}
        \Vert f_t - f^\star \Vert_{\text{var}} + \Vert g_t - 
        g^\star \Vert_{\text{var}} \to 0 \\
        \frac{1}{2} \dotp{\alpha}{f_t + T(g_t, \alpha)} + \dotp{\beta}{g_t + T(f_t, \beta)} 
        \to \Ww(\alpha, \beta).
    \end{gather}
\end{proposition}
% 
This result relies on Proposition 4 from \cite{}, that show convergence with
high probability of stochastic mirror descent with non-convex but locally
coherent functionals.

