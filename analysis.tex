%!TEX root = article.tex


\section{Convergence analysis}

We give three kind of convergence analysis: (i) a stationary distribution convergence property for the random Sinkhorn
algorithm ; (ii) a global convergence property for the online Sinkhorn algorithm without noise ; (iii) a high-probability convergence result for the full online Sinkhorn algorithm.

%%%
\paragraph{Randomized Sinkhorn.}

We first state a result concerning the randomized Sinkhorn algorithm~\eqref{eq:updates}, which corresponds to
\autoref{alg:online_sinkhorn} with step-size $\eta_t = 1$.

\begin{proposition}\label{prop:markov}
    The random Sinkhorn algorithm \eqref{eq:updates} yields a time-homogeneous
    Markov chain ${(f_t, g_t)}_t$ which is $(\hat \alpha_s, \hat \beta_s)_{s \leq
    t}$ measurable, and weak-star converges toward a stationary distribution
    $(F_\infty, G_\infty) \in \Pp(\Cc(\Cc)^2)$ independent of the initialization
    point $(f_0, g_0)$.
\end{proposition}

The proof of this result follows from \citep{diaconis_iterated} convergence theorem on
iterated random functions which are contracting on average. 
%
It uses the fact that
$\Ctrans{\cdot}{\hat \beta}$ and $\Ctrans{\cdot}{\hat \alpha}$ are \textit{always}
contracting, independent of the distributions $\hat \alpha$ and $\hat \beta$.

Note that using the law of large number for Markov chains, the out-of-loop averages
$\exp(-\bar f_t), \exp(-\bar f_t)$ converge to $\EE[\exp(-F_\infty)] \in
\Cc(\Xx)$, that verifies the following fixed point equations
\begin{align}
    \EE[\exp(-F_\infty)] &=
     \dotp{\EE[\exp(G_\infty)] \exp(-C)}{\beta} \\
    \EE[\exp(-G_\infty)] &=
     \dotp{\EE[\exp(F_\infty)] \exp(-C)}{\alpha}.
\end{align}
This fixed point is close to the Sinkhorn fixed point iterations, and converges to them 
get closer as $\varepsilon$ increases, since $\varepsilon \EE[\exp(\pm F_\infty /
\varepsilon)] \to \EE[F_\infty]$ as $\varepsilon \to \infty$. Running the random
Sinkhorn algorithm with out-of-loop averaging fails to provide exactly the dual solution, but 
however defines an approximate solution of the original problem whose accuracy depends on $\epsilon$. 
%
We leave the quantification of this approximation for future work.

%%%
\paragraph{Noise-free Online Sinkhorn.}

Variance reduction is therefore necessary, to ensure that the limit stationary
distribution is deterministic. The following proposition shows that the modified online Sinkhorn algorithm converges in the absence of noise.

\begin{proposition}\label{eq:deterministic}
    We suppose that $\hat \alpha_t = \alpha$, $\hat \beta_t = \beta$ for all
    $t$. Then the updates \eqref{eq:updates} yields a sequence $(f_t, g_t)_t$ such
    that 
    \begin{gather}
        \Vert f_t - f^\star \Vert_{\text{var}} 
        + \Vert g_t - g^\star \Vert_{\text{var}} \to 0 \\
        \frac{1}{2} \dotp{\alpha}{f_t + \Ctrans{g_t}{\alpha}} + \dotp{\beta}{g_t + \Ctrans{f_t}{\beta}} 
         \to \Ww(\alpha, \beta).
    \end{gather}
\end{proposition}
Note that, due to the fact that we perform simultaneous updates and slow them
down, we only obtain the convergence of $f_t \to f^\star + A$, and $g_t \to
g^\star$, where $f^\star$ and $g^\star$ are solutions of \eqref{eq:wass} and $A$
is a constant depending on initialization. This is only a small caveat, as we
can average the potentials and their soft $C$-transform to remove the offset
$C$ (which corresponds to~\eqref{eq-dist-est}). When estimating the spatial derivative of $f^\star$ for training purposes, this is not necessary, as already exposed in Section~\ref{sec:gradient}.

%%%
\paragraph{Online Sinkhorn.}

Finally, we state a result on the complete online Sinkhorn algorithm, which converges with high probability.
 
\begin{proposition}
    Assume that $\Vert f_0 - f^\star \Vert_{\text{var}} < 1$ and $\Vert f_0 -
    f^\star \Vert_{\text{var}} < 1$, $\sum_t \eta_t = \infty$ and $\sum_t
    \eta_t^2 < \infty$. Then, with a probability which can be as close to $1$
    as possible by decreasing the step-sizes,
    \begin{gather}
        \Vert f_t - f^\star \Vert_{\text{var}} + \Vert g_t - 
        g^\star \Vert_{\text{var}} \to 0 \\
        \frac{1}{2} \dotp{\alpha}{f_t + \Ctrans{g_t}{\alpha}} + \dotp{\beta}{g_t + \Ctrans{f_t}{\beta}} 
        \to \Ww(\alpha, \beta).
    \end{gather}
\end{proposition}
% 
This result relies on Proposition 4 from \cite{zhou2017convergence}, that show convergence with
high probability of stochastic mirror descent with non-convex but locally coherent functionals.

